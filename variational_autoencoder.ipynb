{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VFtH9dVCAb03"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           train=True,\n",
        "                                           download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                          transform = transforms.ToTensor(),\n",
        "                                          train = False,\n",
        "                                          download = True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True) # Batch_size, channel_size, height, width\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = 64,\n",
        "                                          shuffle = False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = iter(train_loader)\n",
        "images,labels = next(sample)\n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72iRfHKYBliQ",
        "outputId": "936c35d4-e4eb-4eae-e059-72b6451127ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The encoder and decoder network is preety same as that of autoencoder. The whole concept introduced in variational autoencoder is the reparamaterization trick. If we just sample our latent (z) from normal distribution with calculated mean and variance, we cant do the backpropagation, cause this step is stochastic and not deterministic. so we use the property or shifting and scaling of normal distribution and sample a random noise from standard distribution and then shift by mean and scale by standard deviation."
      ],
      "metadata": {
        "id": "JXM4taw1HlQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# linear variational autoencoder\n",
        "\n",
        "class Linearvariationalautoencoder(nn.Module):\n",
        "\n",
        "  def __init__(self,latent_dim=2):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(28*28,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,28)\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_dim,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,28*28),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.mu = nn.Linear(28, latent_dim)\n",
        "    self.logvar = nn.Linear(28, latent_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.flatten(1)\n",
        "    x = self.encoder(x)\n",
        "\n",
        "    mu = self.mu(x)\n",
        "    logvar = self.logvar(x)\n",
        "    std = torch.exp(0.5 *logvar)\n",
        "\n",
        "    noise = torch.randn_like(std,device = std.device)\n",
        "    z = mu + noise * std\n",
        "\n",
        "    x_hat = self.decoder(z)\n",
        "    x_hat = x_hat.reshape(64,1,28,28)\n",
        "    return x_hat,mu,logvar\n",
        "\n",
        "model = Linearvariationalautoencoder(2).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDYRAsNDCFaq",
        "outputId": "e919f3cd-f93d-4089-d238-4fc65ed1fb74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linearvariationalautoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=28, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=784, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              "  (mu): Linear(in_features=28, out_features=2, bias=True)\n",
              "  (logvar): Linear(in_features=28, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = torch.rand([64,1,28,28]).to(device)\n",
        "x_hat,mu,logvar = model(test_x)\n",
        "print(x_hat.shape)\n",
        "print(mu.shape)\n",
        "print(logvar.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No8QIIPzECc0",
        "outputId": "e3cbd42e-e03c-4697-ecd0-1788ed826339"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 2])\n",
            "torch.Size([64, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lK6puhQEFpgz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}